str(a)
a <- 0:9
a <- as.character(a)
a <- as.numeric(a)
a
str(a)
a <- 0:9
a <- as.double(a)
a
typeof(a)
a <- 0:9
a <- as.logical(a)
a
a <- 10
typeof(a)
a <- as.integer(a)
typeof(a)
a <- 0:9
a <- as.logical(a)
a <- as.integer(a)
a
str(a)
a <- 0:4
str(a)
a <- as.data.frame(a)
a
str(a)
a <- 0:9
a <- as.data.frame(a)
a <- as.list(a)
a
a <- 0:4
a <- as.matrix(a)
a
str(a)
a <- 0:9
a <- as.vector()
a
a <- 0:9
a <- as.vector(a)
a
str(a)
a <- 0:9
a <- as.factor(a)
a
str(a)
data <- c(1, 3, 5, 7, 9)
data_minmax <- scale(data,
center=1,
scale=8)
data_minmax
data_minmax
mode(data)
class(data)
a <- 1:10
a
normalize <- function(a){
return ((a-min(a))/(max(a)-min(a)))
}
normalize(a)
scale(a)
as.vector(scale(a))
as.vector(scale(a))
data <- c(1, 3, 5, 7, 9)
data_zscore <- scale(data)
mean(data_zscore)
sd(data_zscore)
data_zscore
setwd("~")
set("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
setwd("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
# ① sample 함수 #
setwd("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
getwd()
setwd("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
getwd()
source("C:/Users/khl06/Desktop/Mr.GentleKim/TIL/Self-Study/Machine Learning/sujebi(R)/[3] 빅데이터 분석 실무 - 데이터 전처리 작업.R")
setwd("~")
getwd()
`setwd("C:/Users/khl06/Desktop/Mr.GentleKim/TIL/Self-Study/Machine Learning/sujebi(R)")`
s <- sample(x=1:10,
size=5,
replace=FALSE)
s
s <- sample(x=1:10,
size=5,
replace=FALSE)
s
s <- sample(x=1:10,
size=5,
raplace=TRUE)
s
s <- sample(x=1:10,
size=5,
replace=TRUE)
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
install.packages('caret')
library(caret)
library(caret)
ds <- createDataParition(
iris$Species, times=1, p=0.7
)
ds
ds <- createDataPartition(
iris$Species, times=1, p=0.7
)
ds
table(iris[ds$Resample1, "Species"])
table(iris[-ds$Resample1, "Species"])
idx <- as.vector(ds$Resample1)
idx
test_idx <- as.vector(-ds$Resample1)
test_idx
remove(test_idx)
ds_train <- iris[idx, ]
ds_test <- iris[-idx, ]
ds_train
ds_test
library(caret)
ds_k_fold <- createFolds(iris$Species,
k=3,
list=TRUE,
returnTrain=FALSE)   # TRUE : 훈련 데이터의 위치 반환 / FALSE : 평가 데이터의 위치 반환
ds_k_fold
x <- c(0:50, 50)
x
mean(x)
mean(x, trim=0.10)   # trim : 양 극단의 일정 부분을 뺄 때 사용
x <- c(12, 7, 4, -5, NA)
x
mean(x)
mean(x, na.rm=TRUE)
mean(cars$speed)
mean(cars$speed, trim=0.10)
library(dplyr)
cars %>% summarise(
mean01=mean(speed),
mean02=mean(speed, trim=0.1)
)
x <- c(12, 7, 5, -21, 8, -5)
x
median(x)
x <- c(12, 7, 4, -5, NA)
x
median(x)
median(x, na.rm=TRUE)
median(cars$speed)
library(dplyr)
cars %>% summarise(
median01=median(speed)
)
# ③ 최빈수 #
# 직접 함수를 정의하여 구함
table(x)
name(y[which(y==max(y))])
names(y[which(y==max(y))])
names(table(x)[which(table(x)==max(table(x)))])
# which(x, arr.ind=FALSE) : 특정값의 위치를 찾을 수 있는 함수
# arr.ind : 일치 여부를 확인하기 위한 대응값
getmode <- function(x) {
y <- table(x)
names(y)[which(y==max(y))]   # 최빈수 위치 탐색 및 반환
}
names(table(x)[which(table(x)==max(table(x)))])
getmode(x)
x <- c(2, 1, 1, 3, 1)
getmode(x)
# ③ 최빈수 #
# 직접 함수를 정의하여 구함
table(x)
# ① 분산 #
# var(x, y=NULL, na.rm=FALSE, ...)
# ★다른 패키지의 함수와 충돌될 경우 stats::var() 함수로 사용
v <- c(3, 4, 5, 2, 4, 3, 4)
var(v)
var(1:10)
# ② 표준편차 #
# sd(x, na.rm=FALSE)
v <- c(3, 4, 5, 2, 4, 3, 4)
sd(v)
sd(1:10)
# ③ 범위 #
v <- c(1, 7, 3, 5, 11, 4, 6)
diff(range(v))
diff(range(1:10))
library(dplyr)
row_number(x)
min_rank(x)
dense_rank(x)
x <- c(1, 1, 5, 5, 9, 7)
x
library(dplyr)
row_number(x)
min_rank(x)
dense_rank(x)
cars %>%
arrange(dist) %>%
mutate(rank=row_number(dist))
cars %>%
arrange(dist) %>%
mutate(rank=min_rank(dist))
cars %>%
arrange(dist) %>%
mutate(rank=dense_rank(dist))
data(mtcars)
m1 <- lm(hp~., data=mtcars)
m2 <- step(m1, direction="both")
m1 <- lm(hp~., data=mtcars)
m2 <- step(m1, direction="both")
# 변수를 추가하거나 제거하는 작업보다 아무 작업도 하지 않은 현재 상태가
# 가장 AIC가 좋은 207.98이므로 최종 모델로 선정
formula(m2)
library(mlbench)
data(PimaIndiansDiabetes)
pima <- PimaIndiansDiabetes
summary(pima$age)
library(dplyr)
pima <- pima %>% mutate(age_gen=cut(pima$age, c(20, 40, 60, 100), right=FALSE,
label=c("Young", "Middle", "Old")))
table(pima$age_gen)
중요도 <- c('상', '중', '하')
df <- data.frame(중요도)
df
transform(df,
변수1=ifelse(중요도=="중", 1, 0),
변수2=ifelse(중요도=="하", 1, 0))
getwd()
getwd()
getwd()
setwd("C:/Users/khl06/Desktop/Mr.GentleKim/TIL/Self-Study/Machine Learning/sujebi(R)")
getwd()
install.packages("ISLR")
library(ISLR)
str(Default)
head(Default)
summary(Default)
# 분석 모형 구축 - 유의성 검정
library(ISLR)
bankuptcy <- Default
set.seed(202012)           # 동일 모형 생성을 위한 seed 생성
train_idx <- sample(
1:nrow(bankupcty),
size=0.8*nrow(bankruptcy),
replace=FALSE
)
train_idx <- sample(
1:nrow(bankruptcy),
size=0.8*nrow(bankruptcy),
replace=FALSE
)
rm(bankuptcy)
bankruptcy <- Default
set.seed(202012)           # 동일 모형 생성을 위한 seed 생성
train_idx <- sample(
1:nrow(bankruptcy),
size=0.8*nrow(bankruptcy),
replace=FALSE
)
test_idx <- (-train_idx)   # train_idx를 제외하고 test_idx 생성
bankruptcy_train <- bankruptcy[train_idx, ]
bankruptcy_test <- bankruptcy[test_idx, ]
full_model <- glm(default~.,
family=binomial,
data=baknruptcy_train)
full_model <- glm(default~.,
family=binomial,
data=bankruptcy_train)
# ----- #
train_idx
test_idx
# ----- #
bankruptcy
# ----- #
1:nrow(bankruptcy)
# ----- #
View(1:nrow(bankruptcy))
# ----- #
1:nrow(bankruptcy)
train_idx
test_idx
bankruptcy_train == (-bankruptcy_test)
bankruptcy_train = (-bankruptcy_test)
bankruptcy_train = bankruptcy_test
bankruptcy_train == bankruptcy_test
# 분석 모형 구축 - 유의성 검정
library(ISLR)
bankruptcy <- Default
set.seed(202012)           # 동일 모형 생성을 위한 seed 생성
train_idx <- sample(
1:nrow(bankruptcy),
size=0.8*nrow(bankruptcy),
replace=FALSE
)
test_idx <- (-train_idx)   # train_idx를 제외하고 test_idx 생성
# ----- #
1:nrow(bankruptcy)
train_idx
test_idx
# ----- #
bankruptcy_train <- bankruptcy[train_idx, ]
bankruptcy_test <- bankruptcy[test_idx, ]
full_model <- glm(default~.,
family=binomial,
data=bankruptcy_train)
bankruptcy_train == bankruptcy_test
train_idx
test_idx
print("length of train_idx :", length(train_idx))
print("length of test_idx  :", length(test_idx))
length(train_idx)
length(test_idx)
print("length of train_idx :" length(train_idx))
print(length(train_idx))
print("length of train_idx :") print(length(train_idx))
print("length of train_idx :") ; print(length(train_idx))
print("length of train_idx :") , print(length(train_idx))
print("length of train_idx :", length(train_idx))
print("length of test_idx  :", length(test_idx))
cat("length of test_idx  :", length(test_idx))
cat"length of train_idx :", length(train_idx))
cat("length of train_idx :", length(train_idx))
cat("length of test_idx  :", length(test_idx))
cat("length of train_idx :", length(train_idx))
cat("length of test_idx  :", length(test_idx))
test_idx <- bankruptcy[-train_idx]
length(test_idx)
test_idx
test_idx <- bankruptcy(-train_idx)
bankruptcy[train_idx]
test_idx <- bankruptcy[-train_idx, ]
length(test_idx)
test_idx
# 분석 모형 구축 - 유의성 검정
library(ISLR)
bankruptcy <- Default
set.seed(202012)           # 동일 모형 생성을 위한 seed 생성
train_idx <- sample(
1:nrow(bankruptcy),
size=0.8*nrow(bankruptcy),
replace=FALSE
)
test_idx <- (-train_idx)   # train_idx를 제외하고 test_idx 생성
# ----- #
1:nrow(bankruptcy)
train_idx
test_idx
cat("length of train_idx :", length(train_idx))
cat("length of test_idx  :", length(test_idx))
length(train_idx)
length(test_idx)
# ----- #
bankruptcy_train <- bankruptcy[train_idx, ]
bankruptcy_test <- bankruptcy[test_idx, ]
cat("length of bankruptcy_train :", length(bankruptcy_train))
cat("length of bankruptcy_test  :", length(bankruptcy_test))
View(bankruptcy_train)
))
cat("dimension of test_idx  :",dim(test_idx))
cat("dimension of train_idx :", dim(train_idx))
cat("dimension of test_idx  :",dim(test_idx))
dim(train_idx)
cat("dimension of bankruptcy_train :", dim(bankruptcy_train))
cat("dimension of bankruptcy_test  :", dim(bankruptcy_test))
library(ISLR)
bankruptcy <- Default
set.seed(202012)           # 동일 모형 생성을 위한 seed 생성
train_idx <- sample(
1:nrow(bankruptcy),
size=0.8*nrow(bankruptcy),
replace=FALSE
)
test_idx <- (-train_idx)   # train_idx를 제외하고 test_idx 생성
# ----- #
1:nrow(bankruptcy)
train_idx
test_idx
cat("length of train_idx :", length(train_idx))
cat("length of test_idx  :", length(test_idx))
# length(train_idx)   # ★length 함수는 열의 개수...;;
# length(test_idx)
cat("dimension of train_idx :", dim(train_idx))   # NULL
cat("dimension of test_idx  :",dim(test_idx))     # NULL
# ----- #
bankruptcy_train <- bankruptcy[train_idx, ]
bankruptcy_test <- bankruptcy[test_idx, ]
View(bankruptcy_train)
cat("dimension of bankruptcy_train :", dim(bankruptcy_train))
cat("dimension of bankruptcy_test  :", dim(bankruptcy_test))
full_model <- glm(default~.,
family=binomial,
data=bankruptcy_train)
bankruptcy_train == bankruptcy_test
bankruptcy_train != bankruptcy_test
# 분석 모형 구축 - step 함수 이용
step_model <- step(full_model, direction="both")
# 분석 모형 구축 - 변수의 유의성 검정
summary(step_model)
# 분석 모형 구축 - 모형의 유의성 검정
null_deviance <- 2354.0
residual_deviance <- 1287.4
model_deviance <- null_deviance - residual_deviance
pchisq(model_deviance,
df=2,   # 자유도는 선택된 변수의 개수
lower.tail=FALSE)
# 분석 모형 구축 - 다중공선성 확인
install.packages("car")
library(car)
vif(step_model)
# 분석 모형 평가 - 평가용 데이터를 이용한 분류
bankruptcy_test
# 분석 모형 평가 - 평가용 데이터를 이용한 분류
bankruptcy_test[ , -1]
# 분석 모형 평가 - 평가용 데이터를 이용한 분류
pred <- preict(step_model,
newdata=bankruptcy_test[, -1],   # 첫 번째 열을 제외
type="response")
# 분석 모형 평가 - 평가용 데이터를 이용한 분류
pred <- predict(step_model,
newdata=bankruptcy_test[, -1],   # 첫 번째 열을 제외
type="response")
df_pred <- as.data.frame(pred)
df_pred$default <- ifelse(df_pred$pred>=0.5,
df_pred$default <- "Yes",
df_pred$default <- "No")
df_pred$default <- as.factor(df_pred$default)
# 분석 모형 평가 - 혼동 행렬
confusionMatrix(data=df_pred$default,
reference=bankruptcy_test[ , 1])
# 분석 모형 평가 - 혼동 행렬
library(ModelMetrics)
confusionMatrix(data=df_pred$default,
reference=bankruptcy_test[ , 1])
# 분석 모형 평가 - 혼동 행렬
confusionMatrix(data=df_pred$default,
reference=bankruptcy_test[ , 1])
# 분석 모형 평가 - 혼동 행렬
install.packages("caret")
library(caret)
confusionMatrix(data=df_pred$default,
reference=bankruptcy_test[ , 1])
# 분석 모형 평가 - AUC
library(ModelMetircs)
# 분석 모형 평가 - AUC
library(ModelMetrics)
auc(actual=bankruptcy_test[ , 1], predicted=df_pred$default)
str(iris)
head(iris)
summary(iris)
library(rpart)
md <- rpart(Species~., data=iris)   # iris 데이터를 rpart 함수를 이용해 호출
md
plot(md, compress=TRUE, margin=0.5)
text(md, cex=1)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
prp(md, type=2, extra=2)   # type : 트리 표현, extra : 노드의 추가 정보 표기
window()
window(prp)
window(x)
windows(height=10, width=12)
prp(md, type=2, extra=2)   # type : 트리 표현, extra : 노드의 추가 정보 표기
windows(height=10, width=12)
prp(md, type=2, extra=2)   # type : 트리 표현, extra : 노드의 추가 정보 표기
# 분석 모형 평가
ls(md)   # 저장된 변수 확인
md$cptable   # 가지치기 및 트리의 최대 크기를 조절하기 위해 cptable을 사용
# CP : 복잡성 / nsplit : 가지의 분기 수 / rel error : 오류율 / xerror : 교차 검증 오류 / xstd : 교차 검증 오류의 표준오차
plotcp(md)
tree_pred <- predict(md, newdata=iris, type="class")
library(caret)
confusionMatrix(tree_pred, reference=iris$Species)
