std_after <- sd(Pima3$pressure)
std_after
std_diff <- std_after - std_before
print(std_diff)
# ----- #
summary(Pima3)
mean_press <- mean(Pima3$pressure, na.rm=TRUE)
mean_press
std_before <- sd(Pima3$pressure, na.rm=TRUE)
std_before
Pima3$pressure <- ifelse(is.na(Pima3$pressure), mean_press, Pima3$pressure)
std_after <- sd(Pima3$pressure)
std_after
Pima3 <- Pima2 %>% filter(!is.na(glucose) & !is.na(mass))
# ----- #
summary(Pima3)
mean_press <- mean(Pima3$pressure, na.rm=TRUE)
mean_press
std_before <- sd(Pima3$pressure, na.rm=TRUE)
std_before
Pima3$pressure <- ifelse(is.na(Pima3$pressure), mean_press, Pima3$pressure)
std_after <- sd(Pima3$pressure)
std_after
std_diff <- std_after - std_before
print(std_diff)
dim(Pima3)   # 전체 행의 수 확인
# ① ESD(Extreme Studentized Deviation) #
score <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 100000000)
name <- c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L")
df_score <- data.frame(name, score)
esd <- function(x){
return(abs(x-mean(x))/sd(x)<3)
}
esd
esd(score)
library(dplyr)
df_score %>% filter(esd(score))
# ② 사분위수 범위(Q3-Q1) #
score <- c(65, 60, 70, 75, 200)
name <- c("Bell", "Cherry", "Don", "Jake", "Fox")
df_score <- data.frame(name, score)
box_score <- boxplot(df_score$score)
box_score$out
box_score$stats
min_score <- box_score$stats[1]
max_score <- box_score$stats[5]
library(dplyr)
df_score %>% filter(score>=min_score & score<=max_score)
# IQR 함수
score <- c(65, 60, 70, 75, 200)
name <- c("Bell", "Cherry", "Don", "Jake", "Fox")
df_score <- data.frame(name, score)
min_score <- median(df_score$score)-2*IQR(df_score$score)
max_score <- median(df_score$score)+2*IQR(df_score$score)
library(dplyr)
df_score %>% filter(score>=min_score & score<=max_score)
a <- 9
a
str(a)
a <- as.character(a)
a
a <- 0:9
a
str(a)
a <- as.character(a)
a
str(a)
a <- 0:9
a <- as.character(a)
a <- as.numeric(a)
a
str(a)
a <- 0:9
a <- as.double(a)
a
typeof(a)
a <- 0:9
a <- as.logical(a)
a
a <- 10
typeof(a)
a <- as.integer(a)
typeof(a)
a <- 0:9
a <- as.logical(a)
a <- as.integer(a)
a
str(a)
a <- 0:4
str(a)
a <- as.data.frame(a)
a
str(a)
a <- 0:9
a <- as.data.frame(a)
a <- as.list(a)
a
a <- 0:4
a <- as.matrix(a)
a
str(a)
a <- 0:9
a <- as.vector()
a
a <- 0:9
a <- as.vector(a)
a
str(a)
a <- 0:9
a <- as.factor(a)
a
str(a)
data <- c(1, 3, 5, 7, 9)
data_minmax <- scale(data,
center=1,
scale=8)
data_minmax
data_minmax
mode(data)
class(data)
a <- 1:10
a
normalize <- function(a){
return ((a-min(a))/(max(a)-min(a)))
}
normalize(a)
scale(a)
as.vector(scale(a))
as.vector(scale(a))
data <- c(1, 3, 5, 7, 9)
data_zscore <- scale(data)
mean(data_zscore)
sd(data_zscore)
data_zscore
setwd("~")
set("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
setwd("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
# ① sample 함수 #
setwd("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
getwd()
setwd("C:\Users\khl06\Desktop\Mr.GentleKim\TIL\Self-Study\Machine Learning\sujebi(R)")
getwd()
source("C:/Users/khl06/Desktop/Mr.GentleKim/TIL/Self-Study/Machine Learning/sujebi(R)/[3] 빅데이터 분석 실무 - 데이터 전처리 작업.R")
setwd("~")
getwd()
`setwd("C:/Users/khl06/Desktop/Mr.GentleKim/TIL/Self-Study/Machine Learning/sujebi(R)")`
s <- sample(x=1:10,
size=5,
replace=FALSE)
s
s <- sample(x=1:10,
size=5,
replace=FALSE)
s
s <- sample(x=1:10,
size=5,
raplace=TRUE)
s
s <- sample(x=1:10,
size=5,
replace=TRUE)
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
s <- sample(x=1:10,
size=5,
replace=TRUE,
prob=1:10)   # 1에서 10까지 각각 가중치를 주어 표본을 추출
s
install.packages('caret')
library(caret)
library(caret)
ds <- createDataParition(
iris$Species, times=1, p=0.7
)
ds
ds <- createDataPartition(
iris$Species, times=1, p=0.7
)
ds
table(iris[ds$Resample1, "Species"])
table(iris[-ds$Resample1, "Species"])
idx <- as.vector(ds$Resample1)
idx
test_idx <- as.vector(-ds$Resample1)
test_idx
remove(test_idx)
ds_train <- iris[idx, ]
ds_test <- iris[-idx, ]
ds_train
ds_test
library(caret)
ds_k_fold <- createFolds(iris$Species,
k=3,
list=TRUE,
returnTrain=FALSE)   # TRUE : 훈련 데이터의 위치 반환 / FALSE : 평가 데이터의 위치 반환
ds_k_fold
x <- c(0:50, 50)
x
mean(x)
mean(x, trim=0.10)   # trim : 양 극단의 일정 부분을 뺄 때 사용
x <- c(12, 7, 4, -5, NA)
x
mean(x)
mean(x, na.rm=TRUE)
mean(cars$speed)
mean(cars$speed, trim=0.10)
library(dplyr)
cars %>% summarise(
mean01=mean(speed),
mean02=mean(speed, trim=0.1)
)
x <- c(12, 7, 5, -21, 8, -5)
x
median(x)
x <- c(12, 7, 4, -5, NA)
x
median(x)
median(x, na.rm=TRUE)
median(cars$speed)
library(dplyr)
cars %>% summarise(
median01=median(speed)
)
# ③ 최빈수 #
# 직접 함수를 정의하여 구함
table(x)
name(y[which(y==max(y))])
names(y[which(y==max(y))])
names(table(x)[which(table(x)==max(table(x)))])
# which(x, arr.ind=FALSE) : 특정값의 위치를 찾을 수 있는 함수
# arr.ind : 일치 여부를 확인하기 위한 대응값
getmode <- function(x) {
y <- table(x)
names(y)[which(y==max(y))]   # 최빈수 위치 탐색 및 반환
}
names(table(x)[which(table(x)==max(table(x)))])
getmode(x)
x <- c(2, 1, 1, 3, 1)
getmode(x)
# ③ 최빈수 #
# 직접 함수를 정의하여 구함
table(x)
# ① 분산 #
# var(x, y=NULL, na.rm=FALSE, ...)
# ★다른 패키지의 함수와 충돌될 경우 stats::var() 함수로 사용
v <- c(3, 4, 5, 2, 4, 3, 4)
var(v)
var(1:10)
# ② 표준편차 #
# sd(x, na.rm=FALSE)
v <- c(3, 4, 5, 2, 4, 3, 4)
sd(v)
sd(1:10)
# ③ 범위 #
v <- c(1, 7, 3, 5, 11, 4, 6)
diff(range(v))
diff(range(1:10))
library(dplyr)
row_number(x)
min_rank(x)
dense_rank(x)
x <- c(1, 1, 5, 5, 9, 7)
x
library(dplyr)
row_number(x)
min_rank(x)
dense_rank(x)
cars %>%
arrange(dist) %>%
mutate(rank=row_number(dist))
cars %>%
arrange(dist) %>%
mutate(rank=min_rank(dist))
cars %>%
arrange(dist) %>%
mutate(rank=dense_rank(dist))
getwd()
setwd("C:/Users/khl06/Desktop/Mr.GentleKim/TIL/Self-Study/Machine Learning/sujebi(R)")
getwd()
getwd()
# ① 범주형 데이터 #
# 빈도수 탐색
table(mtcars$cyl)
cnt / total
# 백분율 및 비율 탐색
cnt <- table(mtcars$cyl)
total <- length(mtcars$cyl)
cnt / total
cnt/total
cnt <- table(mtcars$cyl)
barplot(cnt,
xlab="기통",
ylab="수량",
main="기통별 수량")
# 별해
prop.table(cnt)
cnt <- table(mtcars$cyl)
pie(cnt,
main="기통별 비율")
# 요약 통계량
summary(mtcars$wt)   # 요약 통계량 출력
head(mtcars$wt)      # 데이터 앞부분 출력
tail(mtcars$wt)      # 데이터 뒷부분 출력
str(mtcars)          # 데이터의 속성을 출력
View(mtcars)         # 뷰어 창에서 데이터 확인
dim(mtcars)          # 데이터의 차원(행, 열)을 출력
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks=5,
xlab="무게",
ylab="수량",
main="무게별 수량")
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks=7,
xlab="무게",
ylab="수량",
main="무게별 수량")
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks107,
xlab="무게",
ylab="수량",
main="무게별 수량")
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks=10,
xlab="무게",
ylab="수량",
main="무게별 수량")
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks=10,
xlab="무게",
ylab="수량",
main="무게별 수량")
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks=2,
xlab="무게",
ylab="수량",
main="무게별 수량")
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks=7,
xlab="무게",
ylab="수량",
main="무게별 수량")
# 개별 데이터의 시각화
wt_hist <- hist(mtcars$wt,
breaks=5,
xlab="무게",
ylab="수량",
main="무게별 수량")
wt_box <- boxplot(mtcars$wt,
main="무게 분포")
# table
table(mtcars$am, mtcars$cyl)
mtcars$label_am <- factor(mtcars$am,
labels = c("automatic", "manual"))
table(mtcars$label_am, mtcars$cyl)
# prop.table
prop_table <- prop.table(table(mtcars$label_am, mtcars$cyl)) * 100
addmargins(round(prop_table, digits=1))   # round 함수에서 digits : 소수점 자릿수
# 빈도수와 비율 시각화
barplot(table(mtcars$label_am, mtcars$cyl),
xlab="실린더 수",
ylab="수량")
# 상관관계 탐색
# cor(x, y, method)   # method : pearson, spearman, kendall
cor_mpg_wt <- cor(mtcars$mpg,
mtcars$wt)
cor_mpg_wt
# 상관관계 시각화
plot(mtcars$mpg, mtcars$wt)
# 그룹 간의 기술 통계량 분석
aggregate(mpg~cyl,
data=mtcars,
FUN=mean)
# 그룹 간의 시각화
boxplot(mpg~cyl, data=mtcars, main="기통별 연비비")
# 그룹 간의 시각화
boxplot(mpg~cyl, data=mtcars, main="기통별 연비")
View(Y)
install.packages("mlbench")
library(mlbench)
data(PimaIndiansDiabetes)
df_pima <- PimaIndiansDiabetes[c(3:5, 8)]
df_pima
PimaIndiansDiabetes
df_pima
df_pima
PimaIndiansDiabetes
str(df_pima)
summary(df_pima)   # 결측치 없음 확인인
cor(x=df_pima, method="pearson")
cor(x=df_pima, method="spearman")
cor(x=df_pima, method="kendall")
window(width=12, height=10)   # 새로운 윈도우에서 시각화 표시
window(width=12, height=10)   # 새로운 윈도우에서 시각화 표시
# corrplot 함수를 처음 사용할 경우 설치 필요
install.packages('corrplot')
library(corrplot)
corrplot(cor(df_pima), method="circle", type="lower")
windows(width=12, height=10)   # 새로운 윈도우에서 시각화 표시
corrplot(cor(df_pima), method="circle", type="lower")
windows(width=12, height=10)   # 새로운 윈도우에서 시각화 표시
corrplot(cor(df_pima), method="circle", type="lower")
windows(width=12, height=10)   # 새로운 윈도우에서 시각화 표시
corrplot(cor(df_pima), method="circle", type="lower")
# 상관계수 검정 - 정규성 만족 여부 검정 : 샤피로-윌크 검정 함수
shapiro.test(df_pima$triceps)
shapiro.test(df_pima$insulin)
cor.test(df_pima$triceps, df_pima$insulin, method="kendall")
getwd()
setwd("C:/Users/khl06/Desktop/Mr.GentleKim/TIL/Self-Study/Machine Learning/sujebi(R)")
getwd()
### (3) 주성분 분석 구축 프로세스 ###
# princomp(x, cor, scores, ...) → cor : 공분산 행렬 또는 상관 행렬(default) 사용 여부, scores : 각 주성분의 점수 계산 여부
# 고유벡터(eigenvaetors)가 loadings 변수에 저장
# 변수들의 선형 결합을 통해 변환된 값을 주성분 점수라고 하고, scores 변수를 통해 확인 가능
iris_pca <- princomp(iris[ , -5],   # Species 제외
cor=FALSE,
scores=TRUE)
summary(iris_pca)   # 누적 기여율
plot(iris_pca, type="l", main="iris 스크리 산점도")   # Scree Plot
iris_pca$loadings
iris$scores
iris_pca$scores
biplot(iris_pca, scale=0, main="iris biplot")   # 주성분 점수 시각화화
# 단순 선형 회귀 수행 예제
summary(lm(Salary~PutOuts, data=Hitters))
View(Hitters)
View(Hitter)
# 단순 선형 회귀 수행 예제
summary(lm(Salary~PutOuts, data=hitters))
# 단순 선형 회귀 수행 예제
summary(lm(Salary~PutOuts, data=Hitters))
summary(Hitters)
# 단순 선형 회귀 수행 예제
install.packages("ISLR")
summary(lm(Salary~PutOuts, data=Hitters))
summary(Hitters)
library(ISLR)
summary(lm(Salary~PutOuts, data=Hitters))
# 다중 선형 회귀 분석 수행 예제
str(Hitters)
head(Hitters)
summary(Hitters)
hitters <- na.omit(Hitters)   # 결측값 제거
summary(hitters)
full_model <- lm(Salary~., data=hitters)
summary(full_model)
full_model <- lm(Salary~., data=hitters)
summary(full_model)
first_model <- lm(Salary~AtBat+Hits+Walks+Cwalks+Division+PutOuts,
data=hitters)
first_model <- lm(Salary~AtBat+Hits+Walks+CWalks+Division+PutOuts,
data=hitters)
fit_model <- step(first_model, direction="backward")
istall.packages("car")
library(car)
install.packages("car")
library(car)
vif(fit_model)
# VIF 수치가 가장 높은 AtBat을 제거한 후 모형을 생성한 후에 다시 다중공선성 문제를 확인
second_model <- lm(Salary~Hits+CWalks+Division+PutOuts,
data=hitters)
vif(second_model)   # 다중공선성 문제 해결
summary(second_model)
# AUC(AUROC : Area Under ROC)
# ★ROC 곡선의 x축은 FPR(False Positive Ratio), y축은 TPR(True Positive Ratio)로 두고
# 아랫부분의 면적인 AUC를 기준으로 모형을 평가
# auc(actual, predicted, ...)
# → actual : 정답인 label의 벡터(numeric, character 또는 factor), predicted : 예측된 값의 벡터
# auc 함수를 처음 사용할 경우 ModelMetrics 패키지 설치 필요
install.packages("ModelMetrics")
library(ModelMetrics)
